{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHBUS4um6cNg"
      },
      "source": [
        "# Dog Anxiety Detection Algorithm using Computer Vision\n",
        "Author: Huidong Hou\n",
        "The goal of this network is designed, to detect dog anxiety level, using knowledge in computer vision. \n",
        "- Note the above was the general goal, but the current version is to detect whether the dog is anxious or not, like a binary classification\n",
        "- The further goal, is to design a probablistic output (probability that the dog is anxious and probability that it is not), if I understand this correctly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOamlz006gCr"
      },
      "source": [
        "## Table of Contents\n",
        "- [1 - Packages](#1)\n",
        "- [2 - Load the Data Set](#2)\n",
        "- [3 - Crafting the Neural Networks](#3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSfa4ame6jny"
      },
      "source": [
        "<a name = '1'></a>\n",
        "# 1 - Data Preparation \n",
        " The following import statements are served to bring in all packages, that will be used by the model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccA7RWCf6lzq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from natsort import natsorted\n",
        "from torchvision import datasets\n",
        "import torchvision\n",
        "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4EQ7poX60r_"
      },
      "source": [
        "## I: Imported Package and Setup\n",
        "Copying the Source code from github, before we use the dataset class to create the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9-5i3MS6_Jr",
        "outputId": "326867ef-e4d2-43f9-ace5-9a2b110eb280"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'BC-Dog-Anxiety-Detection-Project': No such file or directory\n",
            "Cloning into 'BC-Dog-Anxiety-Detection-Project'...\n",
            "remote: Enumerating objects: 1813, done.\u001b[K\n",
            "remote: Counting objects: 100% (181/181), done.\u001b[K\n",
            "remote: Compressing objects: 100% (95/95), done.\u001b[K\n",
            "remote: Total 1813 (delta 88), reused 176 (delta 86), pack-reused 1632\u001b[K\n",
            "Receiving objects: 100% (1813/1813), 365.89 MiB | 34.99 MiB/s, done.\n",
            "Resolving deltas: 100% (388/388), done.\n",
            "Checking out files: 100% (938/938), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -r BC-Dog-Anxiety-Detection-Project\n",
        "!git clone https://github.com/yangcheng99/BC-Dog-Anxiety-Detection-Project.git\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PkB99cF7IJQ"
      },
      "source": [
        "Now I will create the Custom Dataset, using the existed pytorch images. The first is to do with the custom loaddata images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywYfQoKlMhrn"
      },
      "outputs": [],
      "source": [
        "train_data = 'BC-Dog-Anxiety-Detection-Project/Training/'\n",
        "test_data = 'BC-Dog-Anxiety-Detection-Project/Testing/'\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9q7k46LNzUR"
      },
      "source": [
        "The following code is more modifying base on the case from this [website](https://medium.com/analytics-vidhya/creating-a-custom-dataset-and-dataloader-in-pytorch-76f210a1df5d), in case you want to learn more about creating the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZgy6MEF8CYg"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self,path,transforms = None):\n",
        "\t\t   self.imgs_path = path\n",
        "\t\t   file_list = glob.glob(self.imgs_path + \"*\")\n",
        "\t\t   print(file_list)\n",
        "\t\t   self.data = []\n",
        "\t\t   for class_path in file_list:\n",
        "\t\t\t    class_name = class_path.split(\"/\")[-1]\n",
        "\t\t\t    for img_path in glob.glob(class_path + \"/*.jpg\"):\n",
        "\t\t\t\t    self.data.append([img_path, class_name])\n",
        "\t\t   self.class_map = {\"Normal\" : 0, \"Anxious\": 1}  \n",
        "\t\t   self.transforms = transforms\n",
        "       \n",
        "\n",
        "    def __len__(self):\n",
        "    # Return the previously computed number of images\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, class_name = self.data[idx]\n",
        "        #print(f\"fetch query {idx}: cn {class_name}; path: {img_path}\")\n",
        "        img = cv2.imread(img_path,3) #We are reading a greyscale image, for simplicity\n",
        "        img = cv2.resize(img,(416,416))\n",
        "        img = img.transpose([2,1,0])\n",
        "        class_id = self.class_map[class_name]\n",
        "        #print(f\"class_id = {class_id}\")\n",
        "        img_tensor = torch.from_numpy(img)\n",
        "        img_tensor = img_tensor.float()\n",
        "        #print(f\"class_id: {class_id}\")\n",
        "        return img_tensor, class_id\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTNsUwijXf1w"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "# we here use the transforms for ImageNet challenge\n",
        "RGB_MEAN = (0.4914, 0.4822, 0.4465)\n",
        "RGB_STD = (0.2023, 0.1994, 0.2010)\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomCrop((224,224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(RGB_MEAN, RGB_STD),\n",
        "\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomCrop((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(RGB_MEAN,RGB_STD),\n",
        "\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uafUINCmfLkC"
      },
      "source": [
        "Now we will get some sizes of the tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff1yntvNXa3K"
      },
      "source": [
        "The below is some old files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WPualar7FVn",
        "outputId": "d1bc49a9-55bc-4e1a-a8b3-c32c26127353"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['BC-Dog-Anxiety-Detection-Project/Training/Anxious', 'BC-Dog-Anxiety-Detection-Project/Training/Normal']\n",
            "['BC-Dog-Anxiety-Detection-Project/Testing/Anxious', 'BC-Dog-Anxiety-Detection-Project/Testing/Normal']\n",
            "666\n",
            "243\n",
            "167\n",
            "61\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "  train_dataset = CustomDataset(train_data,transforms = transform_train)\n",
        "  test_dataset = CustomDataset(test_data,transforms = transform_test)\n",
        "  print(len(train_dataset))\n",
        "  print(len(test_dataset))\n",
        "\n",
        "  dog_train_data_loader = DataLoader(train_dataset, batch_size = 4,  shuffle = True)\n",
        "  dog_test_data_loader = DataLoader(test_dataset, batch_size = 4, shuffle = True)\n",
        "  print(len(dog_train_data_loader))\n",
        "  print(len(dog_test_data_loader))\n",
        "\n",
        "  #print(train_dataset.length())\n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnHSWTka3r_b"
      },
      "source": [
        "This is for debugging purposes, I think therte is still something wrong with the way the dataset is generated, especially on accessing the indices, or notation, which you can see later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWNW0SDQZN-Q"
      },
      "source": [
        "Now we have finished building our custom dataset, now we can actually run the pre-trained machine ResNet(or maybe just simple CNN network, to train the model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOuofZEcaMd2"
      },
      "source": [
        "<a name = '2'></a>\n",
        "# 2 - Model Creation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lht0XyiAahHo"
      },
      "source": [
        "## Model Download\n",
        "Now we will use the ResNet, downloaded it and train it. The idea is based on Prof.Wei's CSCI3343: Computer Vision's Problem Set 5. I have used two different approaches, the handcrafted resnet, and the pre-trained resnet, both of which have some bugs which i can not figure out what happend."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9rnoI6raNck",
        "outputId": "70fdaba7-c6e7-4de2-c710-8361ceee6657"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        }
      ],
      "source": [
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCPEB6WZcKi2"
      },
      "source": [
        "## Model Modification\n",
        "Now we will modify the last  layer, to predict one layer instead. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkY8WjZbb5-0",
        "outputId": "b0da395a-f358-467c-9cf1-b7797b69fe61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "#### TODO\n",
        "# Hint: what's the input and output size of the last linear layer\n",
        "model.fc = nn.Linear(512,1)\n",
        "\n",
        "torch.cuda.is_available()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBQLm9gYcl_u"
      },
      "source": [
        "## Define Loss Function and Optimizer\n",
        "Now we will define the loss function, but also the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPRR9UlKcvhs"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "def criterion(y_gt, y_pred):\n",
        "    #### TODO\n",
        "    # y_gt is between 0-100 -> scale to 0-1\n",
        "    # y_pred is any real number -> add a sigmoid to squash it to 0-1\n",
        "    y_gt = y_gt/100\n",
        "    y_pred = F.sigmoid(y_pred)\n",
        "    return F.mse_loss(y_pred, y_gt)\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "# freeze the weight for all conv layers\n",
        "# only learn the last linear layer\n",
        "for name,param in model.named_parameters():\n",
        "    if 'fc' in name:\n",
        "        param.requires_grad = True\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "\n",
        "#### TODO\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtQceUtlc-dB"
      },
      "source": [
        "### Data Training\n",
        "  This is the training file, we need to build a data transform to take care of the input before we had out to do the prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MlUOWmpdC6z"
      },
      "outputs": [],
      "source": [
        "#### nothing to change in this code block ####\n",
        "\n",
        "class Config:  \n",
        "  def __init__(self, **kwargs):\n",
        "    # util\n",
        "    self.batch_size = 16\n",
        "    self.epochs = 0\n",
        "    self.save_model_path = '' # use your google drive path to save the model\n",
        "    self.log_interval = 100 # display after number of batches\n",
        "    self.criterion = F.cross_entropy # loss for classification\n",
        "    self.mode = 'train'\n",
        "    for key, value in kwargs.items():\n",
        "      setattr(self, key, value)\n",
        "   \n",
        "class Trainer:  \n",
        "  def __init__(self, model, config, train_data = None, test_data = None):    \n",
        "    self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    self.epochs = config.epochs\n",
        "    self.save_model_path = config.save_model_path\n",
        "    self.log_interval = config.log_interval\n",
        "    self.mode = config.mode\n",
        "\n",
        "    self.globaliter = 0\n",
        "    self.train_loader = None\n",
        "    self.test_loader = None\n",
        "    batch_size = config.batch_size\n",
        "    if self.mode == 'train': # training mode\n",
        "      self.train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=1)      \n",
        "      #self.tb = TensorBoardColab()\n",
        "      self.optimizer = config.optimizer\n",
        "    \n",
        "    if test_data is not None: # need evaluation\n",
        "      self.test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=1)\n",
        "    \n",
        "    self.model = model.to(self.device)\n",
        "    self.criterion = config.criterion # loss function\n",
        "    \n",
        "                \n",
        "  def train(self, epoch):  \n",
        "    self.model.train()\n",
        "    for batch_idx, (data,target) in enumerate(self.train_loader):      \n",
        "      self.globaliter += 1\n",
        "      data, target = data.to(self.device), target.to(self.device)\n",
        "      #print(data.size(), target.size())\n",
        "      self.optimizer.zero_grad()\n",
        "      predictions = self.model(data)\n",
        "\n",
        "      loss = self.criterion(predictions, target)\n",
        "      loss.backward()\n",
        "      self.optimizer.step()\n",
        "\n",
        "      if batch_idx % self.log_interval == 0:\n",
        "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                  epoch, batch_idx * len(data), len(self.train_loader.dataset),\n",
        "                  100. * batch_idx / len(self.train_loader), loss.item()))\n",
        "        #self.tb.save_value('Train Loss', 'train_loss', self.globaliter, loss.item())\n",
        "        #self.tb.flush_line('train_loss')\n",
        "        \n",
        "        \n",
        "  def test(self, epoch, do_loss = True, return_pred = False):\n",
        "    self.model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    pred = []\n",
        "    with torch.no_grad():\n",
        "      print('Start testing...')\n",
        "      for data, target in self.test_loader:\n",
        "        data = data.to(self.device)\n",
        "        predictions = self.model(data)\n",
        "        if return_pred:\n",
        "          pred.append(predictions.detach().cpu().numpy())\n",
        "        if do_loss:\n",
        "            target = target.to(self.device)        \n",
        "            test_loss += self.criterion(predictions, target).item()*len(target)\n",
        "            prediction = predictions.argmax(dim=1, keepdim=True)\n",
        "            correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
        "      if do_loss:\n",
        "          test_loss /= len(self.test_loader.dataset)\n",
        "          accuracy = 100. * correct / len(self.test_loader.dataset)\n",
        "          print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "              test_loss, correct, len(self.test_loader.dataset), accuracy))\n",
        "      \"\"\"\n",
        "      if self.mode == 'train': # add validation data to tensorboard\n",
        "        self.tb.save_value('Validation Loss', 'val_loss', self.globaliter, test_loss)\n",
        "        self.tb.flush_line('val_loss')\n",
        "      \"\"\"\n",
        "      if return_pred:\n",
        "        return np.hstack(pred)\n",
        "  def main(self):\n",
        "    pred = []\n",
        "    if self.mode == 'train':\n",
        "      for epoch in range(1, self.epochs + 1):          \n",
        "          self.train(epoch)\n",
        "          if self.test_loader is not None:\n",
        "            # exist validation data\n",
        "            self.test(epoch)\n",
        "    if (self.save_model_path != ''):\n",
        "        torch.save(self.model.state_dict(), self.save_model_path)\n",
        "    elif self.mode == 'test':\n",
        "      self.test(0)\n",
        "    elif self.mode == 'deploy':          \n",
        "      pred = self.test(0, False, True)\n",
        "      return pred\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code block is a testing code block to see whether a model can be saved into google drive and how, if you want to store it on your local machine, or google drive, you need to change model_path otherwise it will return an error"
      ],
      "metadata": {
        "id": "eTU_mNKo4hvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "model_testing_name = 'testing.pt'\n",
        "model_path = F\"/content/drive/MyDrive/Data/Model/{model_testing_name}\"\n",
        "\n",
        "torch.save(model,model_path)\n",
        "print(model_testing_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3yRxZZCrRxu",
        "outputId": "a8a2169c-61cd-44c2-beb3-a53087fd8ceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testing.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfPppFEkbBEo",
        "outputId": "2224fe1d-7d74-45fa-e1a7-6386c33ea483"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/666 (0%)]\tLoss: 0.097596\n",
            "Start testing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0723, Accuracy: 179/243 (74%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: Using a target size (torch.Size([3, 1])) that is different to the input size (torch.Size([3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 2 [0/666 (0%)]\tLoss: 0.053397\n",
            "Start testing...\n",
            "\n",
            "Test set: Average loss: 0.0616, Accuracy: 179/243 (74%)\n",
            "\n",
            "Train Epoch: 3 [0/666 (0%)]\tLoss: 0.045980\n",
            "Start testing...\n",
            "\n",
            "Test set: Average loss: 0.0555, Accuracy: 179/243 (74%)\n",
            "\n",
            "Train Epoch: 4 [0/666 (0%)]\tLoss: 0.054345\n",
            "Start testing...\n",
            "\n",
            "Test set: Average loss: 0.0501, Accuracy: 179/243 (74%)\n",
            "\n",
            "Train Epoch: 5 [0/666 (0%)]\tLoss: 0.092100\n",
            "Start testing...\n",
            "\n",
            "Test set: Average loss: 0.0465, Accuracy: 179/243 (74%)\n",
            "\n",
            "Train Epoch: 6 [0/666 (0%)]\tLoss: 0.056113\n",
            "Start testing...\n",
            "\n",
            "Test set: Average loss: 0.0412, Accuracy: 179/243 (74%)\n",
            "\n",
            "Train Epoch: 7 [0/666 (0%)]\tLoss: 0.065719\n",
            "Start testing...\n",
            "\n",
            "Test set: Average loss: 0.0342, Accuracy: 179/243 (74%)\n",
            "\n",
            "Train Epoch: 8 [0/666 (0%)]\tLoss: 0.071334\n",
            "Start testing...\n",
            "\n",
            "Test set: Average loss: 0.0339, Accuracy: 179/243 (74%)\n",
            "\n",
            "Train Epoch: 9 [0/666 (0%)]\tLoss: 0.042990\n",
            "Start testing...\n",
            "\n",
            "Test set: Average loss: 0.0293, Accuracy: 179/243 (74%)\n",
            "\n",
            "Train Epoch: 10 [0/666 (0%)]\tLoss: 0.049357\n",
            "Start testing...\n",
            "\n",
            "Test set: Average loss: 0.0286, Accuracy: 179/243 (74%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "#print(device)\n",
        "\n",
        "# set of hyperparameters that is thrown into the model\n",
        "train_config = Config(    \n",
        "    criterion = criterion,\n",
        "    save_model_path = '', # if you like, use your google drive path to save the model (mount google drive first)\n",
        "    log_interval = 100, # display after number of batches\n",
        "    batch_size = 8,\n",
        "    optimizer = optimizer,\n",
        "    epochs = 10,\n",
        ")\n",
        "\n",
        "mvp_model_path = \"mvp.pt\"\n",
        "model_path_mvp = F\"/content/drive/MyDrive/Data/Model/{mvp_model_path}\"\n",
        "\n",
        "model_detection = Trainer(model.to(device), train_config, train_data=train_dataset, test_data=test_dataset).main()\n",
        "torch.save(model_detection,model_path_mvp)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the part I load the model, the code above trains the model and saved it. "
      ],
      "metadata": {
        "id": "LwXz22a64bU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.load(F\"/content/drive/MyDrive/Data/Model/{model_testing_name}\")"
      ],
      "metadata": {
        "id": "xsEfUW5Rj_sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWWaM5GmdKYN"
      },
      "source": [
        "Now we can actually train the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytorch2keras \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOuu-UZo48PY",
        "outputId": "bd6a5765-a324-46b6-ab46-a3c1e6911253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch2keras\n",
            "  Downloading pytorch2keras-0.2.4.tar.gz (21 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from pytorch2keras) (2.8.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from pytorch2keras) (2.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch2keras) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pytorch2keras) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from pytorch2keras) (0.12.0+cu113)\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.11.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 5.6 MB/s \n",
            "\u001b[?25hCollecting onnx2keras\n",
            "  Downloading onnx2keras-0.0.24.tar.gz (20 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx->pytorch2keras) (4.2.0)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from onnx->pytorch2keras) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.2->onnx->pytorch2keras) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->pytorch2keras) (1.14.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->pytorch2keras) (57.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->pytorch2keras) (0.25.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->pytorch2keras) (1.44.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 45.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->pytorch2keras) (1.6.3)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->pytorch2keras) (0.5.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->pytorch2keras) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->pytorch2keras) (2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->pytorch2keras) (14.0.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->pytorch2keras) (3.1.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->pytorch2keras) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->pytorch2keras) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->pytorch2keras) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->pytorch2keras) (1.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->pytorch2keras) (1.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->pytorch2keras) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->pytorch2keras) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->pytorch2keras) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->pytorch2keras) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->pytorch2keras) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->pytorch2keras) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->pytorch2keras) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->pytorch2keras) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->pytorch2keras) (1.8.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->pytorch2keras) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->pytorch2keras) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->pytorch2keras) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->pytorch2keras) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->pytorch2keras) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->pytorch2keras) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->pytorch2keras) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->pytorch2keras) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->pytorch2keras) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->pytorch2keras) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->pytorch2keras) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->pytorch2keras) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->pytorch2keras) (7.1.2)\n",
            "Building wheels for collected packages: pytorch2keras, onnx2keras\n",
            "  Building wheel for pytorch2keras (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch2keras: filename=pytorch2keras-0.2.4-py3-none-any.whl size=29677 sha256=edaa3ffa451dcf11bc31a3fb3d858bab780c6c3a7945d5b8ed3091878e49aaa3\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/4e/ee/8c004883e677ab4283783ffd9433ecf595327889dd367c79b1\n",
            "  Building wheel for onnx2keras (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for onnx2keras: filename=onnx2keras-0.0.24-py3-none-any.whl size=24593 sha256=87b5ad4531d120441b9cb82c02ba29afb06d7fcd60295c2ed99d2ad607c7b6ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/29/29/227fc9f8fed234b12169ae41f979cfadf1dcdbe1b370a5bbb5\n",
            "Successfully built pytorch2keras onnx2keras\n",
            "Installing collected packages: tf-estimator-nightly, onnx, onnx2keras, pytorch2keras\n",
            "Successfully installed onnx-1.11.0 onnx2keras-0.0.24 pytorch2keras-0.2.4 tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pytorch_to_keras(\n",
        "    model, args, input_shapes=None,\n",
        "    change_ordering=False, verbose=False, name_policy=None,\n",
        "    use_optimizer=False, do_constant_folding=False\n",
        "):\n",
        "\n",
        "    # ...\n",
        "\n",
        "    # load a ModelProto structure with ONNX\n",
        "    onnx_model = onnx.load(stream)\n",
        "\n",
        "    # ...\n",
        "    #\n",
        "    k_model = onnx_to_keras(onnx_model=onnx_model, input_names=input_names,\n",
        "                            input_shapes=input_shapes, name_policy=name_policy,\n",
        "                            verbose=verbose, change_ordering=change_ordering)\n",
        "\n",
        "    return k_model"
      ],
      "metadata": {
        "id": "PkQHHJUQ7sN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "import torch\n",
        "\n",
        "example_input = get_example_input() # exmample for the forward pass input \n",
        "pytorch_model = get_pytorch_model()\n",
        "ONNX_PATH=\"./my_model.onnx\"\n",
        "\n",
        "torch.onnx.export(\n",
        "    model=pytorch_model,\n",
        "    args=example_input, \n",
        "    f=ONNX_PATH, # where should it be saved\n",
        "    verbose=False,\n",
        "    export_params=True,\n",
        "    do_constant_folding=False,  # fold constant values for optimization\n",
        "    # do_constant_folding=True,   # fold constant values for optimization\n",
        "    input_names=['input'],\n",
        "    output_names=['output']\n",
        ")\n",
        "onnx_model = onnx.load(ONNX_PATH)\n",
        "onnx.checker.check_model(onnx_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "IUuSzXFe7spq",
        "outputId": "21b12d93-7de3-470d-cc4c-aee50ab36e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-dde26080b163>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mexample_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_example_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# exmample for the forward pass input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpytorch_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pytorch_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mONNX_PATH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./my_model.onnx\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_example_input' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BgQeCQbc78Wi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "MVP_Dog_Anxiety_Detection_Updated.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}